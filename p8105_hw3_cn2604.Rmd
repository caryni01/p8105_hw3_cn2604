---
title: "p8105_hw3_cn2604"
output: github_document
date: "2022-10-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r load_library, echo=FALSE, message=FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)
library(ggridges)
```
# Problem 1
```{r file_p1, echo=FALSE, message=FALSE}
data("instacart")
instacart_df = as_tibble(instacart)
product_num = instacart_df %>% 
  select(product_id) %>% 
  distinct() %>% 
  count()
order_num = instacart_df %>% 
  select(user_id, order_id) %>% 
  distinct() %>% 
  count()
user_num = instacart_df %>% 
  select(user_id) %>% 
  distinct() %>% 
  count()
```
This dataset contains `r nrow(instacart_df)` rows and `r ncol(instacart_df)` columns. Variables are inventories for users and order lists. The product names and order time are also recorded. There are `r product_num` products in `r order_num` orders from `r user_num` different users.

```{r problem_1, echo=FALSE, message=FALSE}
instacart_df %>% 
  count(aisle, sort = TRUE) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items in each aisle",
       y = "Number of Items") +
  theme(axis.text.x = element_text(angle = 90))
```
Here is a table for baking ingredients, dog food care, and packaged vegetables fruits.

```{r problem_1_table, echo=FALSE, message=FALSE}
instacart_df %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>%
  arrange(desc(n)) %>% 
  knitr::kable()
```
Finally is a table for mean hour of the day at Pink Lady Apples and Coffee Ice Cream. 
```{r problem_1_table2, echo=FALSE, message=FALSE}
instacart_df %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(names_from = order_dow, values_from = mean_hour) %>%
  knitr::kable(digits = 2)
```


# Problem 2
```{r clean_file_1, echo=FALSE, message=FALSE}
acce_df = read.csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_number",
    names_prefix = "activity_",
    values_to = "activity_counts"
  ) %>% 
  mutate(
    activity_number = as.numeric(activity_number),
    week_type = factor(case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend",
      TRUE ~ "unknown"
      )
    ),
    .after = day
  )

day_df = acce_df %>% 
  group_by(week, day) %>% 
  summarize(
    total_activity = as.integer(sum(activity_counts))
  )

```

The dataframe after cleaning processes has `r ncol(acce_df)` variables and `r nrow(acce_df)` observations. It includes the week and day variables with an indication of either weekday or weekend. Each one minute interval is turned into a variable named activity_number and activity_counts is the new variable for original activity data.

```{r show_table, echo=FALSE, message=FALSE}
knitr::kable(day_df)
ggplot(day_df, aes(x = day, y = total_activity, fill = week)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Heart activity by week type",
    x = "Day of the week",
    y = "Total activity",
    caption = "Data from P8105 HW3")
```

No apparent trend could be found by the table but the bar plot above suggests that Saturday has least total activity compared to other days of the week.

```{r plot_heart_activity, echo=FALSE, message=FALSE}
acce_df %>% 
  ggplot(aes(x=activity_number, y=activity_counts, color = day)) + 
  geom_point(alpha = .5) + 
  scale_x_continuous(
    breaks = seq(0, 1440, 120),
    labels = c("0", "2:00", "4:00", "6:00","8:00","10:00", "12:00", "14:00", "16:00", "18:00", "20:00", "22:00", "24:00")
  ) +
  scale_color_hue(name = "Day of the week", h = c(300, 0)) +
  labs(
    title = "Heart activity plot",
    x = "Hours of a day",
    y = "Number of activity counts",
    caption = "Data from P8105 HW3")
```

The graph shows that the heart activity rates are highest between 10am to 12pm and 8pm to 10pm throughout the week. The patient seems to have more stable heart activity in Tuesday and Wednesday though he has reached his highest activity rate in Wednesday, which exceeds 7500 activity counts per minute. Overall, the patient maintains an activity rate way below 2500 per minute in most time of a day. 

# Problem 3
```{r load_file_2, echo=FALSE, message=FALSE}
data("ny_noaa")
```

The raw dataframe of ny_noaa has `r ncol(ny_noaa)` variables and `r nrow(ny_noaa)` observations. It has weather station id, date of observation, precipitation, snowfall, snow depth, and maximum and minimum temperatures. For data of precipitation, snowfall, and snow depth, there are `r sum(is.na(ny_noaa$prcp))`, `r sum(is.na(ny_noaa$snow))`, `r sum(is.na(ny_noaa$snwd))` missing values. For tmax and tmin, `r sum(is.na(ny_noaa$tmax))` and `r sum(is.na(ny_noaa$tmin))` of the observations are missing, which loss about a half of helpful information for further analysis. 
```{r clean_file_2, echo=FALSE, message=FALSE}
noaa_df = ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = '-') %>% 
  rename(c("prcp_mm" = "prcp", "snow_mm" = "snow", "snwd_mm" = "snwd")) %>% 
  mutate(
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin)
  )

clean_snow = na.omit(noaa_df$snow_mm)
find_mode = function(v) {
 uniqv = unique(v)
 uniqv[which.max(tabulate(match(v, uniqv)))]
}

```

1. While most of the observations for snowfall are missing, `r find_mode(clean_snow)` mm is the most commonly seen value in the remaining observation. It is reasonable because snowfall is an occasional event in that area and no snow should be observed in normal days.
```{r df_for_plot, echo=FALSE, message=FALSE}
jan_tmax = noaa_df %>% 
  filter( month == "01") %>% 
  select(id, year, tmax) %>% 
  na.omit() %>% 
  mutate(
    year = as.numeric(year)
    ) %>%
  group_by(id, year) %>% 
  summarize(
    mean_tmax_jan = mean(tmax)
  )

july_tmax = noaa_df %>% 
  filter( month == "07") %>% 
  select(id, year, tmax) %>% 
  na.omit() %>% 
  mutate(
    year = as.numeric(year)
    ) %>% 
  group_by(id, year) %>% 
  summarize(
    mean_tmax_july = mean(tmax)
  )

```
```{r plots, echo=FALSE, message=FALSE}
jan_tmax_p = 
  jan_tmax %>% 
  ggplot(aes(x=year, y=mean_tmax_jan, group=id, color = id)) + 
  geom_line() +
  geom_point(alpha=.5) +
  labs(
    title = "Maximum temperature in Jan",
    x = "Year",
    y = "Temperature degree (째C)",
    caption = "Data from P8105 datasets") +
  theme(legend.position = "none") 

july_tmax_p = 
  july_tmax %>% 
  ggplot(aes(x=year, y=mean_tmax_july, group=id, color = id)) + 
  geom_line() +
  geom_point(alpha=.5) +
  labs(
    title = "Maximum temperature in July",
    x = "Year",
    y = "Temperature degree (째C)",
    caption = "Data from P8105 datasets") +
  theme(legend.position = "none") 

jan_tmax_p / july_tmax_p
```

2. The spaghetti plots for maximum temperatures shows that most of the observed maximum temperature in January across all weather station is between -50 to 50 degree Celsius while the range is between 250 to 300 degree Celsius in July. Outliers could be found on the points which are above 100 and below -100 in the plot for Jan, points below 200 could be found in the plot for July.

```{r question_3, echo=FALSE, message=FALSE, warning=FALSE}
tmax_tmin = 
  noaa_df %>% 
  ggplot(aes(x=tmin, y=tmax)) + 
  geom_point(aes(color=year)) +
  labs(
    title = "Maximum temperature versus minimum temperature",
    x = "Minimum temperature (째C)",
    y = "Maximum temperature (째C)",
    caption = "Data from P8105 datasets") +
  theme(legend.position = "bottom") 

snow_den =
  noaa_df %>% 
  filter(snow_mm > 0 & snow_mm < 100) %>% 
  ggplot(aes(x=snow_mm, color = year)) +
  geom_density(alpha=.5) +
  labs(
    title = "Snowfall distribution across years",
    x = "Snowfall (mm)",
    y = "Density",
    caption = "Data from P8105 datasets") +
  theme(legend.position = "bottom") 

tmax_tmin + snow_den
```
3. Figures above are tmax vs tmin for the full dataset and snowfall distribution between 0 to 100 mm across the years.

